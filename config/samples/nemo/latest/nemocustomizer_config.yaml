---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-training-config
  namespace: nemo
data:
  training: |
    # Optional additional configuration for training jobs
    container_defaults:
      imagePullPolicy: IfNotPresent

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-model-config
  namespace: nemo
data:
  models: |
    # -- Llama 3.2 3B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3.2 3B Instruct model.
    meta/llama-3.2-3b-instruct:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI.
      model_uri: ngc://nvidia/nemo/llama-3_2-3b-instruct:2.0
      # -- Path where model files are stored.
      model_path: llama32_3b-instruct
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 1
          num_nodes: 1
          tensor_parallel_size: 1
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 3000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3.2 1B model configuration.
    # @default -- This object has the following default values for the Llama 3.2 1B model.
    meta/llama-3.2-1b:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI for Llama 3.2 1B model.
      model_uri: ngc://nvidia/nemo/llama-3_2-1b:2.0
      # -- Path where model files are stored.
      model_path: llama32_1b
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 1
          num_nodes: 1
          tensor_parallel_size: 1
        - training_type: sft
          finetuning_type: all_weights
          num_gpus: 1
          num_nodes: 1
          tensor_parallel_size: 1
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 1000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3.2 1B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3.2 1B Instruct model.
    meta/llama-3.2-1b-instruct:
      # -- Whether to enable the model.
      enabled: true
      # -- NGC model URI for Llama 3.2 1B Instruct model.
      model_uri: ngc://nvidia/nemo/llama-3_2-1b-instruct:2.0
      # -- Path where model files are stored.
      model_path: llama32_1b-instruct
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 1
          num_nodes: 1
          tensor_parallel_size: 1
        - training_type: sft
          finetuning_type: all_weights
          num_gpus: 1
          num_nodes: 1
          tensor_parallel_size: 1
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 1000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3 70B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3 70B Instruct model.
    meta/llama3-70b-instruct:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI for Llama 3 70B Instruct model.
      model_uri: ngc://nvidia/nemo/llama-3-70b-instruct-nemo:2.0
      # -- Path where model files are stored.
      model_path: llama-3-70b-bf16
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 4
          num_nodes: 1
          tensor_parallel_size: 4
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 70000000000
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3.1 8B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3.1 8B Instruct model.
    meta/llama-3.1-8b-instruct:
      # -- Whether to enable the model.
      enabled: true
      # -- NGC model URI for Llama 3.1 8B Instruct model.
      model_uri: ngc://nvidia/nemo/llama-3_1-8b-instruct-nemo:2.0
      # -- Path where model files are stored.
      model_path: llama-3_1-8b-instruct_0_0_1
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 1
        - training_type: sft
          finetuning_type: all_weights
          num_gpus: 8
          num_nodes: 1
          tensor_parallel_size: 4
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 8000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3.1 70B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3.1 70B Instruct model.
    meta/llama-3.1-70b-instruct:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI for Llama 3.1 70B Instruct model.
      model_uri: ngc://nvidia/nemo/llama-3_1-70b-instruct-nemo:2.0
      # -- Path where model files are stored.
      model_path: llama-3_1-70b-instruct_0_0_1
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 4
          num_nodes: 1
          tensor_parallel_size: 4
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 70000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Phi-4 model configuration.
    # @default -- This object has the following default values for the Phi-4.
    microsoft/phi-4:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI for Phi-4 model.
      model_uri: ngc://nvidia/nemo/phi-4:1.0
      # -- Path where model files are stored.
      model_path: phi-4
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 1
          num_nodes: 1
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 14659507200
      # -- Model precision format.
      precision: bf16
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"

    # -- Llama 3.3 70B Instruct model configuration.
    # @default -- This object has the following default values for the Llama 3.3 70B Instruct model.
    meta/llama-3.3-70b-instruct:
      # -- Whether to enable the model.
      enabled: false
      # -- NGC model URI for Llama 3.3 70B Instruct model.
      model_uri: ngc://nvidia/nemo/llama-3_3-70b-instruct:2.0
      # -- Path where model files are stored.
      model_path: llama-3_3-70b-instruct_0_0_1
      # -- Training options for different fine-tuning methods.
      training_options:
        - training_type: sft
          finetuning_type: lora
          num_gpus: 4
          num_nodes: 1
          tensor_parallel_size: 4
      # -- Micro batch size for training.
      micro_batch_size: 1
      # -- Maximum sequence length for input tokens.
      max_seq_length: 4096
      # -- Number of model parameters.
      num_parameters: 70000000000
      # -- Model precision format.
      precision: bf16-mixed
      # -- Template for formatting prompts.
      prompt_template: "{prompt} {completion}"
