---
# NIM Service for LLM specific NIM with LoRAs
apiVersion: apps.nvidia.com/v1alpha1
kind: NIMService
metadata:
  name: meta-llama-3-2-1b-instruct
  namespace: nim-service
spec:
  image:
    repository: nvcr.io/nim/meta/llama-3.2-1b-instruct
    tag: "1.8"
    pullPolicy: IfNotPresent
    pullSecrets:
      - ngc-secret
  authSecret: ngc-api-secret
  env:
    - name: NIM_PEFT_SOURCE
      value: "/model-store/<lora-directory>" # Update with the absolute <lora-directory> path inside the PVC
  storage:
    pvc: # Pre-created PVC with downloaded loras
      name: meta-llama-3-2-1b-instruct
  replicas: 1
  resources:
    limits:
      nvidia.com/gpu: 1
  expose:
    service:
      type: ClusterIP
      port: 8000
